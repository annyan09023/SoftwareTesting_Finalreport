\pagenumbering{arabic} \setcounter{page}{1}
\chapter{Introduction}


\section{Background}
Information explosion is a term that describes the rapidly
increasing amount of published information and the effects of this
abundance of data. As the amount of available data grows, the
effective and efficient management of the information becomes more
difficult, leading to information overload or information fatigue.
The explosion problem of video data, in particular, posts more
technical challenges due to the fact that audio-visual features are
unorganized and unordered in nature. Video retrieval, aiming to mine
and search semantic knowledge from an over-abundance of video
dataset, has drawn increasing attentions from both extant web search
engines (e.g., Yahoo!, Google and so on) and scientific researchers.
However, the video usually carries a versatile semantic message
which has immediate meaning for a human. But for a computer, it is
far from the truth. This discrepancy between the machine computable
low-level features and its semantic interpretation by human subjects
is commonly referred to as the \emph{semantic gap}
\cite{ArnoldW.M.Smeulders:IEEETPAMI:2000}. Bridging semantic gap has
long been recognized as a key factor in enabling semantic-based
video retrieval.

Early efforts aiming to bridge the semantic gap focused on the
feasibility of mapping low-level features, e.g. color, pitch and
texture, directly to high-level semantic concepts such as commercial
\cite{R.Lienhart:IEEECMCS:1997}, nature \cite{J.R.Smith:IEEEMM:1997}
and baseball \cite{Y.Rui:ACMM:2000}. Many dedicated detectors have
been developed for this intuitive purpose, which map low-level
features to single semantic concept based on simple decision rules.
The detector-specific-approaches, however, become impractical and
intractable with the demand of large-scale automatic annotation of
video archives. It is almost impossible to develop a dedicated
detector for each possible concept, as there are just too many
concepts. Instead of developing concept-specific detectors, a recent
trend has therefore been shifting to develop generic detectors.
Specifically, with a set of concept-specific training examples,
generic detectors are trained separately with single approach
without considering concept-specific knowledge
\cite{MilindR.Naphade:IEEEICOME:2000,A.Amir:TRECVID:2003,C.G.M.Snoek:NISTTRECVID:2005}.
This has enlightened the possibility of developing large-scale
concept detectors, ending up a multimedia ontology suitable for both
video annotation and search.

The core of generic-based approaches mainly relies on the paradigm
of supervised learning \cite{CeesG.M.Snoek:ACMMM:2006}. The major
limitation, nevertheless, is the need of large amount of labeled
examples for training. The labeling of multimedia data is generally
a labor intensive, subjective and erroneous process. The researchers
have indeed looked forward a large shared annotation dataset for
concept detector learning. To cope with the demand, initiated by Lin
et al. \cite{C.Y.Lin:TRECVID:2003}, a common annotation effort was
recently started for the TREC Video Retrieval Evaluation (TRECVID
Workshop) 2005 benchmark. It has yielded a large accurate set of
groundtruth including a lexicon of 39 concepts
\cite{M.R.Naphade:2005}. Driven by this effort, various sets of
annotated concepts, such as Medmill's 101 machine-learned detectors
\cite{CeesG.M.Snoek:ACMMM:2006} and the recent collaborative
undertaking development of Large-Scale Concept Ontology for
Multimedia (LSCOM) \cite{Milind.Naphade:IEEEMM:2006}, have become
publicly available.

However, such a widely collaborative annotation effort, with such a
large amount of shared groundtruth, can never reach the richness of
human-know vocabularies. New concepts and new examples will have to
be annotated, when we face any new domain. More seriously, different
people tend to use different terms in annotating the same concept
during labeling, resulting in label ambiguity. Even for the same
user, he/she will trend to use different terms in different context.
To deal with this problem, ontologies
\cite{C.Fellbaum:1998,H.Liu:BTTJ:2004} were developed to structure
terms employed by user, which can make descriptions more consistent.
Exploiting ontology on video domain can embed the inherently
uncertain tagging, generated either by machine or human, in a
semantically rich context. With the multimedia ontology, we can
disambiguate various interpretations and find concepts that are more
general and useful for retrieval. As the video domain is broad and
in practice contains any topic, a large and domain independent
ontology is necessary.

\section{Ontology and Multimedia Ontology}
In philosophy, ontology is the study of the kinds of things that
exist. Ontologies are often said, colorfully,``to carve the world at
its joints". In information science, however, it is unrealistic,
when we realize that the world is too big to be carved. What we say
ontology is therefore referred to domain ontology, which describe
the body knowledge of a domain. Different from traditional domain
knowledge, an ontology analysis clarifies the structure of knowledge
by identifying the basic conceptualizations needed to talk about all
instances, recognizing their types, and relating the topology to
additional constraints. A well-structured knowledge representation
is easy to be shared with others who have similar needs in that
domain, thereby eliminating the need for replicating the
knowledge-analysis process. Shared ontologies can thus form the
basis for domain-specific knowledge-representation languages. In
contrast to the previous generation of knowledge-representation
languages (e.g KL-One \cite{R.J.Brachman:CS:1985}), these languages
are content rich; they have a large number of terms that embody a
complex content theory of the domain
\cite{B.Chandrasekaran:IEEEIS:1999}.

The current interest in ontologies come from the alternation of
focus between content theories and mechanism theories. Many
mechanisms, such as rule systems, frame languages, neural nets,
fuzzy logic, constraint propagation, or unification, are proposed as
exciting secret of making intelligent machines. With such wonderful
mechanisms, however, we cannot do much without a good content
theory. Moreover, we often recognize that once a good content theory
is reached, many different mechanisms might be used equally well to
implement effective systems, all using essentially the same content
\cite{B.Chandrasekaran:IEEEE:1994}. Ontologies are quintessentially
content theories. Thus far, they have played important roles in
information systems, natural language understanding (NLU) and
knowledge-based systems. In the domain of multimedia, ontology is
regarded as an emerging, yet natural, tool to bridge the semantic
gaps as a result of annotation ambiguity due to fuzziness of
audio-visual information. Ideally, ontology should be able to deal
with the richness of natural vocabularies, not only in textual but
also audio-visual domain.

Given the term Multimedia Ontology, people might usually refer to
some standard controlled vocabularies and classification schemes for
multimedia. For example, MPEG-7 has standardized more than 140
classification schemes that describe properties of multimedia
content. Similarly, TGM-I provides a large thesaurus for cataloging
graphical material. There are several multimedia controlled
vocabularies available. However, these standard schemes have
received little attention from the multimedia research community,
mostly because many of the terms in these schemes are not suitable
for automated tagging. For example, the MPEG-7 Genre Classification
Scheme (urn:mpeg:mpeg7:cs:GenreCS:2001), which is used to classify
programs based on their content or subject matter, defines terms
such as``special events" and``remarkable people." The terms might be
useful for classifying multimedia content but do not lend them well
to automated extraction. Such subjective concepts also make it
difficult for two annotators to completely agree, which further
complicates this issue. This highlights the third critical
requirement for the multimedia concept ontology: the feasibility of
automated extraction \cite{Milind.Naphade:IEEEMM:2006}.

Multimedia ontology helps to identify the body classes, their
properties and the relationship between them. It will provide the
reasoning strategy a well-structured knowledge base. On the other
side, the reasoning strategy also has impact on the development of a
multimedia ontology. We could in fact explain this in a common
sense: how we build a thing is strongly related with how we use it,
and vice versa.

\section{Concept-based Video Search and Ontology Reasoning}
Recent applications of using multimedia ontology are mainly for
concept-based video search, as illustrated in
Figure~\ref{fg-semantic_gap}.
%
The sensory gap from user queries to raw data is bridged with a pool
of concepts enriched with general-purpose vocabularies, for
instance, from ontology (e.g., WordNet) and external information
(e.g., Internet). Based on such concepts, a set of concept detectors
is developed to represent the high-level semantics. The detectors
are automatically learnt with training examples described by
multi-modality features. Given a user query, the best set of
concepts that can describe the semantic of query is reasoned through
the vocabularies. A search list is then produced by ranking items
(e.g., shots) according to their signal responses to the selected
concept detectors.
%
\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{semantic_gap.eps}
\caption{General framework of concept-based video retrieval.}
\label{fg-semantic_gap}
\end{figure}
%

Under the concept-based retrieval framework as depicted in
Figure~\ref{fg-semantic_gap}, an apparent issue is that, given the
concept set, the mapping ambiguity between queries and concepts
needs to be carefully resolved. A common solution is to consider the
mapping through ontology reasoning
\cite{CeesG.M.Snoek:IEEETM:2006,Anthony.Hoogs:CVPR:2003,Alejandro.Jaimes:ICOIVR:2003,Yi.Wu:IEEEICOME:2004,M.R.Naphade:2005},
or more precisely selecting the concepts which minimize the
linguistic distance with query terms. The mapping is normally done
with the shared knowledge topology such as WordNet
\cite{C.Fellbaum:1998}. A fundamental question is: whether the
ontology reasoning can provide a common ground for the consistence
reasoning of concept similarities?
%
\begin{figure}
 \centering \subfigure[]
{\includegraphics[width=0.48\textwidth]{cfo.eps}\label{fig:cfo}}
 \centering \subfigure[]
{\includegraphics[width=0.48\textwidth]{OSS.eps}\label{fig:oss}}
%\subfigure[]
%{\includegraphics[width=0.24\textwidth]{os2mode.eps}\label{fig:os2}}
\caption{Reasoning with (a) ontology, reasoning is done in a
subgraph without a global view of the whole structure, (b) OSS,
concepts are projected into the space according to their relations
with selected vantage (basis) concepts.}\label{fig:CFO_OSS}
\end{figure}
%
Take Figure~\ref{fig:CFO_OSS}(a) as an example, let concepts $a$ to
$e$ as children and $v_1$ to $v_3$ as ancestors. Using ontology
reasoning approach such as Resnik \cite{Philip.Resnik:IJCAI:1995}
which measures similarity of two concepts with Information Content
(IC) \cite{Philip.Resnik:IJCAI:1995} of their nearest common
ancestor, the concept pairs $(a,b)$ and $(a,c)$ could have the same
similarity equals to IC of $v_1$, although $(a,c)$ sharing another
ancestor $v_2$ and intuitively should be more alike. In this case,
supposing $a$ is a query item, concept selection is hard to be made
between $b$ and $c$. On the other hand, the similarity scores of
$(d,e)$ and $(a,b)$ cannot be reasonably compared as they reside in
different parts of the ontology which carry different statistic and
structural information.
%
In brief, the reasoning is {\em locally} determined in a subgraph
without a global ontological view. Such mapping strategy indeed
causes the similarity scores of query terms and concepts not
directly comparable, resulting in less meaningful matching when
finding the ``best concepts'' to interpret query semantics.

\section{Ontology-enriched Semantic Space}
In this report, we propose a novel model called Ontology-enriched
Semantic Space (OSS) to enable the uniform and \emph{global}
comparison of concept pairs by providing a {\em computable}
platform. With reference to Figure~\ref{fig:CFO_OSS}(b), the
semantic space is represented as a linear space spanned with a set
of concepts enriched with ontology knowledge. These concepts of OSS
can be viewed as the ``vantage'' points
\cite{RobertoF.Santos.Filho:ICDE:2001,CaetanoTraina.Jr.:VLDB:2007}
\cite{Malcolm.Slaney:ICME:2002,A.Berenzweig:ICME:2003,Jules.Vleugels:PR:2002}
of the original ontology space. Supposing the ancestors $v_1$ to
$v_3$ of Figure~\ref{fig:CFO_OSS}(a) are selected as the vantage
concepts of OSS, then one can linearly project the concepts $a$-$e$
to the metric space according to their ontological relation with the
selected vantage concepts through conventional ontology reasoning.
Such framework indeed sights several opportunities. First, the
vantage concepts provide a high coverage of semantic space, and are
probably the ones that should be developed if they are feasible to
be built with the current technology. Secondly, in contrast to the
examples in Figure~\ref{fig:CFO_OSS}(a), the space guarantees
\emph{global} consistency in comparing the concept pairs like
$(a,b)$, $(a,c)$ and $(d,e)$.

An intuitive explanation of OSS is that the space is linearly
constructed to model the available set of concepts. The expressive
power of OSS is linguistically spanned with a set of vantage
concepts, which is easier to generalize, not only to the available
concept detectors but also to the unseen concepts.

%However, some of the vantage concepts of OSS may have inter-concept
%correlation, which causes their corresponding vectors are not
%strictly orthogonal to each other. This will bias the measurement of
%similarity. To solve this problem, we further model the
%orthogonality of semantic space, resulting in an Orthogonal
%Ontology-enriched Semantic Space ($OS^2$). In contrast to OSS,
%$OS^2$ performs spectral decomposition to transform the semantic
%space into a novel space with orthogonal base. With reference to
%Figure~\ref{fig:CFO_OSS}(c), the base ($B_1$, $B_2$ and $B_3$) in
%$OS^2$ are not formed by the real concepts. They are, however,
%linear combinations of basis concept vectors of OSS, and are more
%powerful in terms of expressive and generalization abilities for
%having the orthogonal property which optimally covers the semantic
%space. Thus a more consistent way of comparing concept similarity
%scores can be guaranteed in $OS^2$.

\section{Organization of This Report}
With OSS, we explore several search related tasks including concept
selection and detector fusion in this report. The major
contributions of our works are briefly summarized as follows:
%
\begin{itemize}
\item
{\em Scalability}: Building detectors for all concepts is impossible
and not necessarily \cite{A.Hauptmann:CIVR:2007,W.H.Lin:ICME:2006}.
A practical question is which detectors should be developed given
the information at hand. Compared to recent works in
\cite{W.H.Lin:ICME:2006}, OSS provides another novel view of
selecting concepts which have higher generalization ability in query
answering.


\item
{\em Query-concept mapping}: With OSS, the mapping is no longer a
local similarity comparison. Global consistency is ensured so that
the selection of concepts becomes meaningful.


\item
{\em Query disambiguation}: User queries are mostly ambiguous. We
explore OSS to predict the search intention by finding the exact
senses of query terms.
\end{itemize}

The remaining chapters are organized as follows.
Chapter~\ref{chp:related_work} briefly describes the current
state-of-the-art about multimedia ontology and concept-based video
search. Chapter~\ref{chp:modelingSS} presents the main idea of
modeling and constructing OSS. Chapter~\ref{chp:properties} analyzes
the properties of OSS. Finally, Chapter~\ref{chp:experiments}
presents experiments and Chapter~\ref{chp:conc} concludes this
report.
