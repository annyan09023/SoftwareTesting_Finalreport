\chapter{Related Work}
\label{chp:related_work} Despite the fact that bridging semantic gap
is simply an intuitive idea, it has taken almost a decade's research
effort. Various methodologies have been addressed so far, which
probably imply the difficulty and diversity of the problem domain.
In this chapter, we briefly review the existing approaches and
outline the major research challenges.

Traditional video retrieval methods assume that low-level features
correspond to the high-level semantic of queries. Features often
come from video associated textual resources such as closed captions
and transcript generated by automatic speech recognition (ASR)
\cite{M.Brown:ACMM:1995,B.Adams:TREC:2002}. In addition, some visual
features, like shape in \cite{A.Del.Bimbo:IEEETPAMI:1997}, texture
in \cite{W.Ma:MS:1999}, color in \cite{Th.Gevers:IEEETIP:2000} are
extracted from images. Recent methods aiming to bridge the gap by
developing dedicate detectors using both text and image features,
were proposed in
\cite{R.Lienhart:IEEECMCS:1997,J.R.Smith:IEEEMM:1997,Y.Rui:ACMM:2000}.
These so called concept-specific detectors then face the problem of
scalability, which gives birth to generic detectors
\cite{MilindR.Naphade:IEEEICOME:2000,A.Amir:TRECVID:2003,CeesG.M.Snoek:ACMMM:2006}.
The biggest challenge of deriving a multimedia ontology based on
generic detectors is the demand of vocabulary size and training
sample. Both demands are driven by system usage and development
respectively. Naturally, increasing vocabulary size implies the need
for more training samples. Nonetheless, training data is always
limited while the size of natural vocabulary is numerically
uncountable. Towards this end, an ideal multimedia ontology should
have the capacity to extend knowledge with minimum incremental
update. Specifically, the ontology should have the ability of
inferring unseen vocabularies from the numerically limited
concepts/detectors through reasoning, with the assistant of external
resources such as Web.

\section{Concept Set}
The use of multimedia ontology for narrowing semantic gap has been
recognized as a vital direction to approach semantic based
retrieval. Current ontologies consider mainly the identifying and
inclusion of high-level concepts that are feasible to be detected
and useful for retrieval. Available concept sets for the
constriction of ontology or reasoning include the 1000-concept LSCOM
\cite{Milind.Naphade:IEEEMM:2006}, 101 concepts from MediaMill
concepts \cite{CeesG.M.Snoek:ACMMM:2006}, and 39 Lite-LSCOM by
TRECVID community benchmark \cite{M.R.Naphade:2005}. The 39 concepts
from TRECVID 2005 benchmark is the most popular one, including
concepts like``Face",``Person", and``Sports". Later on, MediaMill
extends it to a larger set of 101 concepts
\cite{CeesG.M.Snoek:ACMMM:2006}, in which some specific named person
are appended e.g.``G.Bush jr",``I.Allawi", and``T.Blair". As a
collaborative effort, LSCOM further enlarge the set to 1000 concepts
\cite{Milind.Naphade:IEEEMM:2006}, aiming to standardize multimedia
semantics. What set of semantic concepts should the community focus
on? It is still an ongoing research topic. However, the final goal
for the moment should be a set of appropriate size, suitable for
automatic tagging techniques. In this set, right concepts are
included, which form a basis of semantic space. Further unseen terms
could be easily represented respect to this basis.

\section{Existing Ontologies}
Ontology is a formulated and sharable knowledge base, believed to be
supplementing each other with mechanism theories. It is primarily
used in text retrieval. Distinguishing from traditional
keywords-based retrieval methods, the ontology makes the relation
between property values and agents explicit, telling which property
value is connected using which property to which element of the
subject mater \cite{A.Th.(Guus).Schreiber:IEEEIS:2001}. Consider
"chimpanzee under large tree." Reduced to keywords,``large" can
refer to the chimpanzee or the tree. The ontology provides relations
between the terms. Inheritance relation, for example, is very
important to control means to widen or constrain a query.

Bringing ontology to multimedia domain is a comparatively new
research topic; even several attempts have been made in recent
years. Starting form year 2003, Hoogs \cite{Anthony.Hoogs:CVPR:2003}
add semantics to visual detectors by establishing links with a
general-purpose ontology. In their methods, visual characteristics
taking information of scene and motion are attached terms in
Wordnet. Respecting to relation information from Wrodnet, Bayesian
method is employed to handle large uncertainties, sparse data and
prior knowledge.

At the same year, instead of making use of existing ontology,
\cite{Alejandro.Jaimes:ICOIVR:2003,Alejandro.Jaimes:IEEEICOME:2003}
proposed a semi-automatic method to construct multimedia ontology.
Their idea is to learn key concepts and relations from training
textual data by using a standard text mining tools implemented in
KAON \cite{A.Maedche:IEEEDEB:2002}. A rules-based reasoning is
performed on the semi-automatic constructed ontology. During the
constructing, however, too much human judgments are required to
determine the types of relations detected, e.g. properties or
inheritance.

Limited by the semantic gap, as we have seen, it is difficult to
link low-level features and high-level concepts together. Mezaris
\cite{Mezaris:IEEETCSVT:2004} expand their image ontology
\cite{Mezaris:ICIP:2003} to multimedia domain, in which an
intermediate level is set up aiming to bridge the low-level visual
features and high-level concepts. The intermediate level serves to
map digital low-level features to corresponding semantic ones, e.g.
color value between a predefined range will be mapped to``red" or
"blue" and so on. After the mapping, an image region will be
presented by series of higher feature like dominate color, shape,
and background/foreground. Then intermediate features will be used
to infer higher concepts in object ontology, which named but did not
be presented in their paper. In sense, this architecture seems
reasonable. However, in their work, it just provides filters
effectively eliminating some irrelevant annotation. The final
decision has to be made by user in a traditional relevance feedback
manner.

Instead of using complex ontology, Wu \cite{Yi.Wu:IEEEICOME:2004}
employed a simple hierarchical decision tree for
multi-classification. After constructing the each single concept
model independently, ontology-based concept learning improves the
accuracy of individual concept by considering the possible influence
relations between concepts based on predefined ontology hierarchy.
The main idea, called boosting factor, is to boost the precision of
concepts by taking influences from more reliable ancestors. By the
Shrinkage theory \cite{Andrew.McCallum:ICML:1998}, parameter
estimates in data-sparse children toward the estimates of the
data-rich ancestors in ways that are probably optimal under
appropriate condition \cite{Yi.Wu:IEEEICOME:2004}. New parameter
estimate of child could therefore be created by a linear
interpolation of all hierarchy nodes from the root to the child. The
simple hierarchy ontology used in this work, however, mixes
relations like hierarchical and homonym together. It might be a
disadvantage limiting the extending of this ontology.

Similar with the idea of Hoogs, MediaMill
\cite{CeesG.M.Snoek:IEEETM:2006} add semantics to detectors for
video retrieval. A set of machine learned concept detectors that are
enriched with semantic descriptions and semantic structure obtained
from WordNet. Their kernel of reasoning is based on semantic
similarity measurement. The detector having maximum similarity score
with given query will be regarded as the most relevant one. However,
the noisy information included in Wordnet sometimes causes the
unreliable of similarity measure, and affects the correct selection
of concepts.

Recently, Luo \cite{Hangzai.Luo:ACMMM:2006} proposed a
domain-dependent ontology for Medical Video Annotation, in which
some terms of medical are built for bridging the semantic gap. They
proposed a multi-task boosting framework to do the reasoning,
slightly similar with \cite{Yi.Wu:IEEEICOME:2004}. The ontology is
domain-dependent and has unproved capability to extend to other
larger domain.

The content of video, most of the time is unlimited, which will tend
to include information from all kinds of domain. This is a possible
difficulty of building ontology for multimedia. Neither by building
an entire ontology manually nor by extending a single ontology
including general knowledge, \cite{Huan.Wang:ACMM:2006} provides an
alternative way to build ontology for multimedia domain, combining
ontologies of different domains. In their work, they take advantage
of combing an animal domain ontology, a textual description ontology
and a visual description ontology together. Reasoning is made by an
existing system RACER \cite{Volker.Haarslev:ACMSIGIRR:2001}. This
method takes less effort to construct ontology and easy to be
extended. However, keeping the consistence between employed
ontologies might be a potential issue for it.

\section{Ontology Reasoning}
\label{sec:ontology_reasoning} To select appropriate
concepts/detectors,
\cite{Yu-Gang.Jiang:NISTTRECVID:2006,CeesG.M.Snoek:IEEETM:2006,Shih-Fu.Chang:NISTTRECVID:2005}
 proposed methods based on semantic similarity
\cite{Philip.Resnik:IJCAI:1995}, which indicates the relatedness of
two words by querying Wordnet. Concepts/detectors, which are most
related (have highest semantic similarity) with original query text,
are selected. Thus, semantic similarity, which is still an ongoing
research topic of linguistic computing, becomes the kernel of such
approaches. There exist several semantic similarity measures,
different in terms of whether they exploit the structure or
information content of ontologies. Among them, Resnik measure
\cite{Philip.Resnik:IJCAI:1995} is the most popular one which has
been employed by
\cite{CeesG.M.Snoek:IEEETM:2006,Shih-Fu.Chang:NISTTRECVID:2005}. In
\cite{CeesG.M.Snoek:IEEETM:2006,Tat-Seng.Chua:NISTTRECVID:2006},
they utilize both concept description and ontology for similarity
measure. During offline indexing, each concept is manually linked to
1-6 synsets of Wordnet based on the concept description. During
mapping, the matching between query terms and the linked synsets of
a concept are evaluated with Resnik measures. A best matched concept
is then found for semantic retrieval. In
\cite{Tat-Seng.Chua:NISTTRECVID:2006,Shi-YongNeo:ICOIVR:2006}, a
more sophisticated framework is proposed. Both query terms and
concept descriptions are Wordnet expanded. More importantly they
fuse the statically expanded lexical information with dynamic
correlation by calculating the time-dependent mutual information
from external news sources. Specifically, with the time sensitive
expansion, the co-occurrence terms are found from the external
sources and used to dynamically weight the importance of concepts
across time. The final similarity is fused jointly with Resnik
measure, time-dependent information, as well as the detection
confidence of concepts.

There indeed exist several measures for semantic measures, such as
LCH \cite{C.Leacock:1998}, HSO \cite{G.Hirst:1997}, WUP
\cite{W.Zhibiao:AMACL:1994}, RES \cite{Philip.Resnik:IJCAI:1995},
LIN \cite{Dekang.Lin:AMACL:1997}, JCN \cite{JayJ.Jiang:ICRCL:1997},
Lesk \cite{M.Lesk:AICSD:1986}, Gloss Vector (Vect)
\cite{Siddharth.Patwardhan:ACLWMSSBCLPT:2006} and Pairwise Gloss
Vector (VP) \cite{Siddharth.Patwardhan:ACLWMSSBCLPT:2006}. LCH, HSO,
and WUP use path length information, while the remaining utilize
information content (RES, LIN, JCN) and the definition of word sense
(Lesk, Vect, VP). With a hierarchical tree of an Ontlogy like
WordNet, denote $D$ as the depth and $I$ as the information content
of a concept, $L$ as the path length between two concepts, and
$p_{ij}$ as the common ancestor of concepts $c_i$ and $c_j$. $D$
indicates the specificity of a concept, the larger the more
specific. Intuitively, the longer the $L$ path length is, the more
two concepts are differ to each other. The information concept $I$
is a measurement of the volume of information contained in a
concept. The measures are defined as (Formula of HSO has not been
included for its complicity. Reader could refer to
\cite{G.Hirst:1997}.)
\begin{eqnarray}
LCH(c_i,c_j) & = & -\log \frac{L(c_i,c_j)}{2\delta}\\
WUP(c_i, c_j) & = & \frac{2 D(p_{ij})}{L(c_i,c_j)+2D(p_{ij}))}\label{eqn:wup} \\
RES(c_i,c_j) & = & I(p_{ij})\\
 LIN(c_i,c_j) & = & \frac{2 I(p_{ij})}{I(c_i)+I(c_j)} \\
 JCN(c_i,c_j) & = & \frac{1}{I(c_i)+I(c_j)-2I(p_{ij})}
\end{eqnarray}
where $\delta$ is the maximum depth of WordNet. The information
content is estimated based on the one-million-word Brown Corpus of
American English \cite{N.Francis:1982}. Lesk utilizes the number of
shared words (overlaps) in the definitions (glosses) of concepts.
Vect represents concepts as gloss vectors using the co-occurrence
information derived from glosses. The cosine similarity between
gloss vectors is used to measure the concept relatedness. VP is
basically similar to Vect, except in the way it augments the glosses
of concepts with adjacent glosses.

\section{Ontology-based Video Search}
While encouraged by the richness of ontology reasoning approaches,
the issue of building concept ontology for query-concept mapping
remains open and unsolved
\cite{S.F.Chang:NISTTRECVID:2006,C.G.M.Snoek:NISTTRECVID:2006,W.H.Lin:ICME:2006}.
Multimedia and visual based ontology construction has been
previously addressed in
\cite{CeesG.M.Snoek:IEEETM:2006,Anthony.Hoogs:CVPR:2003,Hangzai.Luo:ACMMM:2006,L.Hollink:ACMMM:2005}.
The construction mostly involves the manual mapping of visual
elements to textual concept entities provided by shared
vocabularies. In \cite{Anthony.Hoogs:CVPR:2003}, WordNet is extended
with visual tags describing properties such as visibility, motion
and frequency of occurrence. In \cite{L.Hollink:ACMMM:2005}, based
on WordNet and MPEG-7, a visual ontology is created by linking
visual and general concepts. In view of the richness of human
vocabularies and the need for domain experts in tagging or creating
links, the scalability of these approaches is still remain unclear.
A relatively straightforward approach is recently proposed in
\cite{CeesG.M.Snoek:IEEETM:2006} by directly attaching concept
detectors to WordNet synsets. The semantically enriched detectors
can thus utilize contextual information provided by WordNet.
%In addition to the ontologies built on the basis of
%general-purpose vocabularies, domain specific multimedia ontology is
%also investigated in \cite{}.
%In \cite{}, two animal domain
%ontologies are constructed separately for textual and visual
%descriptions. The study indicates that the ontologies are useful for
%image retrieval.
Different from the existing ontology construction
\cite{CeesG.M.Snoek:IEEETM:2006,Anthony.Hoogs:CVPR:2003,L.Hollink:ACMMM:2005},
our approach utilizes the concept inter-relatedness to construct an
ontology-enriched semantic space. The space is computable and more
viable for query-concept mapping, particularly for fusing the
outputs of multiple concept detectors.

Depending on the types (visual or text) of queries, the mapping from
queries to concepts can be performed with detectors
\cite{M.Campbell:TRECVID:2006} or resources such as ontology
\cite{Shi-YongNeo:ICOIVR:2006,CeesG.M.Snoek:IEEETM:2006,C.G.M.Snoek:NISTTRECVID:2006},
text description \cite{CeesG.M.Snoek:IEEETM:2006} or co-occurrence
statistic \cite{M.Campbell:TRECVID:2006,Shi-YongNeo:ICOIVR:2006}.
%
For queries with image or video examples, the responses of detectors
basically indicate the likelihood of corresponding concepts present
in queries. For instance, the best confident detector is selected
for search in \cite{CeesG.M.Snoek:IEEETM:2006}.
%
For text queries, the mapping is usually performed through ontology
reasoning.
% which includes two steps: word sense disambiguation (WSD)
%and concept selection. A popular algorithm for WSD is Lesk algorithm
%\cite{} which automatically extracts the actual sense of query
%terms.
Various ontology similarity measures introduced in
Section~\ref{sec:ontology_reasoning} could be directly employed for
computing the association between terms and concepts.
%Popular measures include Resnik \cite{Philip.Resnik:IJCAI:1995}, JCN
%\cite{JayJ.Jiang:ICRCL:1997} and WUP \cite{W.Zhibiao:AMACL:1994}
%which consider ontological properties such as the specificity and
%information content of a concept, and the linguistic path length
%between two concepts.
%
In addition to ontology reasoning, other approaches for mapping text
queries are to compare queries against the text descriptions
associated with concepts \cite{CeesG.M.Snoek:IEEETM:2006} or to
expand queries with related terms \cite{Shi-YongNeo:ICOIVR:2006}.
The expanded terms as well as their weights can be learnt from
training examples \cite{M.Campbell:TRECVID:2006} or external
information such as Internet \cite{Shi-YongNeo:ICOIVR:2006}.
%
Nevertheless, due to the difficulty of obtaining training examples,
particularly for cross-domain video search, corpus training is
generally not scalable.

A different strategy of query-to-concept mapping is via the
construction of semantic space or vector space for modeling
concepts. The pioneering work in
\cite{Apostol(Paul).Natsev:ACMSIGKDD:2004,JohnR.Smith:ICME:2003}
constructs a semantic space, or more precisely a vector space,
formed by the set of available concept detectors. In this space, a
retrieval item (e.g., shot) is represented as a vector of model
scores. The scores are computed based on the signal responses of the
detectors to the item. Contrasting to other approaches based on
ontology reasoning
\cite{CeesG.M.Snoek:IEEETM:2006,Xiao-Yong.Wei:ACMMM:2007}, no
specific detector is selected, but rather all detectors are involved
in the video search though each detector carries different weights.
In \cite{Xirong.Li:CIVR:2007}, the idea of tf-idf originated from
information retrieval, which weights the importance of a detector
according to its appearance frequency, is adopted to further improve
the search performance of vector space representation.
%

\section{Anchor Selection} OSS could be treated as a feature space,
in which each dimension represents the soft membership in one of the
selected anchor concepts. Seen this way, this work is related to
anchor space approaches such as
\cite{RobertoF.Santos.Filho:ICDE:2001,CaetanoTraina.Jr.:VLDB:2007}
for database indexing, \cite{Malcolm.Slaney:ICME:2002} for audio
retrieval and indexing, \cite{A.Berenzweig:ICME:2003} for
classification of music, \cite{Jules.Vleugels:PR:2002} for image
retrieval. The kernel of anchor-based approaches are, which and how
many concepts should be are selected as anchors. In
\cite{Malcolm.Slaney:ICME:2002,A.Berenzweig:ICME:2003,Jules.Vleugels:PR:2002},
anchors are simply determined by human assignment. More precisely,
\cite{RobertoF.Santos.Filho:ICDE:2001,CaetanoTraina.Jr.:VLDB:2007}
selects anchors by using a algorithm named``Hull of Foci" (HF),
which greedily search concepts which are mostly far apart in
original space as anchors. The number of anchors is determined with
\emph{correlation fractal dimension}, which is an approximation of
intrinsic dimension of a space and could be estimated by algorithms
like Box-counting
\cite{Christos.Faloutsos:ACMSIGMODICMD:2000,C.Traina.Jr.:XVBSDSBBD:2000}.

\section{Summary}
As discussed in this chapter, ontologies, as a potential direction
to bridge the gap in a more formal manner, facilitate problem
analysis and solution design. However, two issues remain unclear:
(1) which and how many concepts should be selected to develop
detector? (2) which semantic similarity measure is the best for
ontology reasoning, or more precisely, query-concept mapping?
Following chapters will answer these questions.
